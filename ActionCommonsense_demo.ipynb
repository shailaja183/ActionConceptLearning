{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MfHUo6UsBdn"
      },
      "source": [
        "# Demo of ActionCommonsense\n",
        "\n",
        "**Purpose**: Run our Action Comet model for custom image input. Specifically,\\\n",
        "**Input**: Image (we currently limit to actions/objects typically found in kitchen)\\\n",
        "**Output**: Text describing\\\n",
        "(i) **actions** that are happening in the image and objects that participate in action (e.g. boiling egg)\\\n",
        "(ii) **pre-conditions** for the action happening in the image (e.g. water is a pre-condition for boiling)\\\n",
        "(iii) most likely **before and after** (effects) scenarios (e.g. contents of egg will become solid)\\\n",
        "-----------\\\n",
        "You need to swich between two python notebooks for this demo\\\n",
        "(i) **Detectron_demo notebook**: Takes user specified image, detect objects and extract features from it\\\n",
        "(ii) **ActionComet_demo notebook**: Takes image features and generate inference\n",
        "\n",
        "# Step 1: Detectron_demo notebook\n",
        "Note: GPU required to run this script.\n",
        "\n",
        "Simply run cells 1-9 to set up proper environment and define useful functions.\n",
        "\n",
        "Then upload any image of your choice (we currently limit to actions/objects typically found in kitchen) under Google Drive directory action-comet/action_images/. Then provide name of your uploaded image file under 'filename' variable in cell 10.\n",
        "\n",
        "Run cell 10 to obtain following for your uploaded image (i) detected objects in the image (ii) extracted image features (iii) .json and .pkl files containing image metadata, which are required by inference module.\n",
        "\n",
        "# Step 2: ActionCommonsense_demo notebook\n",
        "Note: GPU is not required but highly recommended to run this script.\n",
        "\n",
        "Simply run cells 1-4 to set up proper environment.\n",
        "\n",
        "Run cell 5 to obtain inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeppFjGFFZBa"
      },
      "outputs": [],
      "source": [
        "# cell 1\n",
        "# mount google drive and move to the directory visual-comet\n",
        "from google.colab import drive\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/action-commonsense/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAu4xzspMdje",
        "outputId": "875234d4-c905-48a3-d85e-5b15bb92c494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [419 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [799 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,082 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [842 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [960 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [857 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,213 kB]\n",
            "Fetched 6,510 kB in 2s (3,899 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libcasa-python3-6' for regex 'python3.6'\n",
            "Note, selecting 'libpython3.6-stdlib' for regex 'python3.6'\n",
            "Note, selecting 'python3.6-2to3' for regex 'python3.6'\n",
            "The following additional packages will be installed:\n",
            "  libcasa-casa6\n",
            "The following NEW packages will be installed:\n",
            "  libcasa-casa6 libcasa-python3-6\n",
            "0 upgraded, 2 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 1,088 kB of archives.\n",
            "After this operation, 4,238 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcasa-casa6 amd64 3.4.0-2build1 [1,000 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcasa-python3-6 amd64 3.4.0-2build1 [88.2 kB]\n",
            "Fetched 1,088 kB in 1s (1,220 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libcasa-casa6:amd64.\n",
            "(Reading database ... 129824 files and directories currently installed.)\n",
            "Preparing to unpack .../libcasa-casa6_3.4.0-2build1_amd64.deb ...\n",
            "Unpacking libcasa-casa6:amd64 (3.4.0-2build1) ...\n",
            "Selecting previously unselected package libcasa-python3-6:amd64.\n",
            "Preparing to unpack .../libcasa-python3-6_3.4.0-2build1_amd64.deb ...\n",
            "Unpacking libcasa-python3-6:amd64 (3.4.0-2build1) ...\n",
            "Setting up libcasa-casa6:amd64 (3.4.0-2build1) ...\n",
            "Setting up libcasa-python3-6:amd64 (3.4.0-2build1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "update-alternatives: error: alternative path /usr/bin/python3.6 doesn't exist\n",
            "update-alternatives: error: no alternatives for python3\n",
            "Python 3.10.6\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.6-distutils\n",
            "E: Couldn't find any package by glob 'python3.6-distutils'\n",
            "E: Couldn't find any package by regex 'python3.6-distutils'\n",
            "--2023-07-25 16:49:49--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2605506 (2.5M) [text/x-python]\n",
            "Saving to: ‘get-pip.py.1’\n",
            "\n",
            "get-pip.py.1        100%[===================>]   2.48M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-07-25 16:49:49 (28.0 MB/s) - ‘get-pip.py.1’ saved [2605506/2605506]\n",
            "\n",
            "Collecting pip<22.0\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "     |████████████████████████████████| 1.7 MB 3.0 MB/s            \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pip-tools 6.13.0 requires pip>=22.2, but you have pip 21.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-21.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 0s (4,228 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 129832 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (21.3.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "     |████████████████████████████████| 2.1 MB 2.5 MB/s            \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.3.1\n",
            "    Uninstalling pip-21.3.1:\n",
            "      Successfully uninstalled pip-21.3.1\n",
            "Successfully installed pip-23.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# cell 2\n",
        "# installation of python 3.6 (it is mandatory to have this version of python in order to run following script)\n",
        "\n",
        "# this script will ask for a user prompt after a while with following header\n",
        "# Press <enter> to keep the current choice[*], or type selection number:\n",
        "# Enter the section number that points to python3.6\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
        "!sudo update-alternatives --config python3\n",
        "!python --version\n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "# uncomment above command only when you do installation for the first time\n",
        "!python get-pip.py\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgRTklbxMdpy",
        "outputId": "317a20e9-3649-4548-efa8-b4224830dd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: python3.6: command not found\n"
          ]
        }
      ],
      "source": [
        "# cell 3\n",
        "# check if python3.6 is correctly installed\n",
        "!python3.6 -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2K-43eZMdmr",
        "outputId": "a2d065e5-4ed2-49ae-9182-6d2a9e0aba51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: python3.6: command not found\n"
          ]
        }
      ],
      "source": [
        "# cell 4\n",
        "# install necessary packages/libraries\n",
        "!python3.6 -m pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywk6rA9BWnZw"
      },
      "source": [
        "Inference using checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUTfXCajs0s_"
      },
      "source": [
        "== Ex: Peel a banana\n",
        "\n",
        "intent ~ high-level goal (for doing an action)\\\n",
        "before ~ precondition\\\n",
        "after ~ effect\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "d = torch.load(os.path.join('/content/drive/MyDrive/action-commonsense/experiments/image-inference-80000-ckpt', 'pytorch_model.bin'))\n",
        "w = d['transformer.detector.regularizing_predictor.weight']\n",
        "print(w)\n",
        "print(w.size())\n",
        "b = d['transformer.detector.regularizing_predictor.bias']\n",
        "cuda0 = torch.device('cuda:0')\n",
        "x = torch.tensor([0.],device=cuda0)\n",
        "#print(x)\n",
        "w1 = torch.tensor(w[-1],device=cuda0)\n",
        "print(w1.size())\n",
        "w1 = w1.view(1,2048)\n",
        "print(w1)\n",
        "upw = len(torch.cat((b, x), 0))\n",
        "upb = len(torch.cat((w, w1), 0))\n",
        "d['transformer.detector.regularizing_predictor.weight'] = upw\n",
        "d['transformer.detector.regularizing_predictor.bias'] = upb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hEtXrINQMq1",
        "outputId": "b9eb2db7-8cf0-4dd0-9381-b47a42b27bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0045, -0.0208, -0.0156,  ..., -0.0238, -0.0116,  0.0357],\n",
            "        [ 0.0083,  0.0123, -0.0151,  ...,  0.0099, -0.0083, -0.0354],\n",
            "        [ 0.0196,  0.0299, -0.0498,  ...,  0.0026,  0.0021,  0.0211],\n",
            "        ...,\n",
            "        [-0.0207, -0.0084, -0.0213,  ...,  0.0153, -0.0061, -0.0061],\n",
            "        [-0.0043, -0.0021, -0.0004,  ...,  0.0230,  0.0675,  0.0035],\n",
            "        [-0.0008, -0.0196, -0.0121,  ...,  0.0265, -0.0174, -0.0033]],\n",
            "       device='cuda:0')\n",
            "torch.Size([91, 2048])\n",
            "torch.Size([2048])\n",
            "tensor([[-0.0008, -0.0196, -0.0121,  ...,  0.0265, -0.0174, -0.0033]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-f29a729bdd43>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  w1 = torch.tensor(w[-1],device=cuda0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVne1vEuQRr2",
        "outputId": "44c3d4b1-5230-426c-e5a1-bbb7b612c00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: python3.6: command not found\n"
          ]
        }
      ],
      "source": [
        "# cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/action-commonsense/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/action-commonsense/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/action-commonsense/experiments/image-inference-80000-ckpt --split custom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.6 ./scripts/evaluate_generation.py --gens_file /content/drive/MyDrive/action-commonsense/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json --refs_file /content/drive/MyDrive/action-commonsense/visualcomet_data/val_annots.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6whyBtU1QKfB",
        "outputId": "bae01e9d-36ea-4119-aa49-4ce606675112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0it [00:00, ?it/s]\r6it [00:00, 33644.15it/s]\n",
            "PTBTokenizer tokenized 464 tokens at 1041.86 tokens per second.\n",
            "PTBTokenizer tokenized 170 tokens at 642.45 tokens per second.\n",
            "{'testlen': 141, 'reflen': 137, 'guess': [141, 111, 81, 54], 'correct': [29, 7, 3, 1]}\n",
            "ratio: 1.0291970802844586\n",
            "Bleu_1 0.20567375886378955\n",
            "Bleu_2 0.11388773957510763\n",
            "Bleu_3 0.07831832563023393\n",
            "Bleu_4 0.054613386280059045\n",
            "METEOR 0.08404953397155623\n",
            "CIDEr 0.14590907228953712\n",
            "Saving to: /content/drive/MyDrive/action-commonsense/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.evaluate.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YZYQmT3tAFI"
      },
      "source": [
        "== Ex: Cut a cake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tAcrKDiuibM",
        "outputId": "e0df1eb2-b8a7-4be8-88af-5626a0aa965c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/12/2023 22:38:40 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "*** main /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/vocab.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/merges.txt\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/added_tokens.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/special_tokens_map.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/tokenizer_config.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|b_img|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|e_img|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|b_ev|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|e_ev|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|b_pl|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|e_pl|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|e_in|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|before|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|intent|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|after|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det0|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det1|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det2|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det3|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det4|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det5|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det6|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det7|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det8|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det9|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det10|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det11|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det12|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det13|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det14|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det15|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det16|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det17|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det18|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det19|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det20|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det21|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det22|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det23|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det24|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det25|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det26|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det27|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det28|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det29|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det30|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det31|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det32|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det33|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det34|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det35|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det36|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det37|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det38|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det39|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det40|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det41|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det42|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det43|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det44|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det45|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det46|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det47|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det48|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Adding <|det49|> to the vocabulary\n",
            "06/12/2023 22:38:40 - INFO - transformers.tokenization_utils -   Assigning ['<|b_img|>', '<|e_img|>', '<|b_ev|>', '<|e_ev|>', '<|b_pl|>', '<|e_pl|>', '<|e_in|>', '<|before|>', '<|intent|>', '<|after|>', '<|det0|>', '<|det1|>', '<|det2|>', '<|det3|>', '<|det4|>', '<|det5|>', '<|det6|>', '<|det7|>', '<|det8|>', '<|det9|>', '<|det10|>', '<|det11|>', '<|det12|>', '<|det13|>', '<|det14|>', '<|det15|>', '<|det16|>', '<|det17|>', '<|det18|>', '<|det19|>', '<|det20|>', '<|det21|>', '<|det22|>', '<|det23|>', '<|det24|>', '<|det25|>', '<|det26|>', '<|det27|>', '<|det28|>', '<|det29|>', '<|det30|>', '<|det31|>', '<|det32|>', '<|det33|>', '<|det34|>', '<|det35|>', '<|det36|>', '<|det37|>', '<|det38|>', '<|det39|>', '<|det40|>', '<|det41|>', '<|det42|>', '<|det43|>', '<|det44|>', '<|det45|>', '<|det46|>', '<|det47|>', '<|det48|>', '<|det49|>'] to the additional_special_tokens key of the tokenizer\n",
            "06/12/2023 22:38:40 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:38:40 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "06/12/2023 22:38:40 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/pytorch_model.bin\n",
            "Namespace(cache_postfix=None, data_dir='/content/drive/MyDrive/visual-comet/visualcomet_data/', device=device(type='cpu'), do_sample=1, gen_batch_size=1, include_image=True, include_text=True, inference_type='all', length=20, max_seq_len=128, model_name_or_path='/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt', model_type='gpt2_vc', n_gpu=0, no_cuda=False, num_samples=5, output_file=None, overwrite_cache=False, padding_text='', prompt='', seed=42, split='val', task=None, temperature=1.0, top_k=0, top_p=0.9, use_all_dets=False)\n",
            "/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n",
            "*** main val\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data\n",
            "cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "train_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/train_annots.json\n",
            "val_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/val_annots.json\n",
            "test_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/test_annots.json\n",
            "Creating features from dataset file at /content/drive/MyDrive/visual-comet/visualcomet_data with cache file name: /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "val 3\n",
            "Encoding Data:   0% 0/3 [00:00<?, ?it/s]***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting a cake', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 257, 12187, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting a cake', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 257, 12187, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting a cake', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 257, 12187, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 3/3 [00:00<00:00, 894.69it/s]\n",
            "test 41439\n",
            "Encoding Data:   0% 0/41439 [00:00<?, ?it/s]***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 41439/41439 [00:37<00:00, 1114.77it/s]\n",
            "Saving features into cached file %s /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "Only relevant dets\n",
            "Only relevant dets\n",
            "  0% 0/3 [00:00<?, ?it/s]Image: cut/Ex1.jpeg\n",
            "Event Text: 1 is cutting a cake\n",
            "Place: inside\n",
            "Inference Type: intent\n",
            "Inference Generations: ['get the piece of cake to becut', 'get ready to put on the birthday cake', 'use cutting tools', 'get a cake together', 'cut a piece of cake']\n",
            " 33% 1/3 [00:55<01:51, 55.65s/it]Image: cut/Ex1.jpeg\n",
            "Event Text: 1 is cutting a cake\n",
            "Place: inside\n",
            "Inference Type: before\n",
            "Inference Generations: ['get the knife', 'get hired to do the catering', 'get ready for the party', 'attend the wedding', 'decide to make a dinner']\n",
            " 67% 2/3 [01:53<00:57, 57.15s/it]Image: cut/Ex1.jpeg\n",
            "Event Text: 1 is cutting a cake\n",
            "Place: inside\n",
            "Inference Type: after\n",
            "Inference Generations: ['get in a fight with a little girl', 'get distracted by a noise', 'put food on the cutting board', 'perform his performance', 'cut a piece of the cake']\n",
            "100% 3/3 [02:50<00:00, 56.80s/it]\n",
            "Saved to /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n"
          ]
        }
      ],
      "source": [
        "# cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/visual-comet/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt --split val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HISCr9DtLdF"
      },
      "source": [
        "== Ex: Wash carrots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkG9WqMDujtb",
        "outputId": "eb84a9d2-44e4-4494-f914-ed49df1657d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/12/2023 22:42:53 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "*** main /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/vocab.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/merges.txt\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/added_tokens.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/special_tokens_map.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/tokenizer_config.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|b_img|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|e_img|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|b_ev|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|e_ev|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|b_pl|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|e_pl|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|e_in|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|before|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|intent|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|after|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det0|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det1|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det2|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det3|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det4|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det5|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det6|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det7|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det8|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det9|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det10|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det11|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det12|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det13|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det14|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det15|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det16|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det17|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det18|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det19|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det20|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det21|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det22|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det23|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det24|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det25|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det26|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det27|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det28|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det29|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det30|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det31|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det32|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det33|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det34|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det35|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det36|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det37|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det38|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det39|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det40|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det41|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det42|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det43|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det44|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det45|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det46|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det47|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det48|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Adding <|det49|> to the vocabulary\n",
            "06/12/2023 22:42:53 - INFO - transformers.tokenization_utils -   Assigning ['<|b_img|>', '<|e_img|>', '<|b_ev|>', '<|e_ev|>', '<|b_pl|>', '<|e_pl|>', '<|e_in|>', '<|before|>', '<|intent|>', '<|after|>', '<|det0|>', '<|det1|>', '<|det2|>', '<|det3|>', '<|det4|>', '<|det5|>', '<|det6|>', '<|det7|>', '<|det8|>', '<|det9|>', '<|det10|>', '<|det11|>', '<|det12|>', '<|det13|>', '<|det14|>', '<|det15|>', '<|det16|>', '<|det17|>', '<|det18|>', '<|det19|>', '<|det20|>', '<|det21|>', '<|det22|>', '<|det23|>', '<|det24|>', '<|det25|>', '<|det26|>', '<|det27|>', '<|det28|>', '<|det29|>', '<|det30|>', '<|det31|>', '<|det32|>', '<|det33|>', '<|det34|>', '<|det35|>', '<|det36|>', '<|det37|>', '<|det38|>', '<|det39|>', '<|det40|>', '<|det41|>', '<|det42|>', '<|det43|>', '<|det44|>', '<|det45|>', '<|det46|>', '<|det47|>', '<|det48|>', '<|det49|>'] to the additional_special_tokens key of the tokenizer\n",
            "06/12/2023 22:42:53 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:42:53 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "06/12/2023 22:42:53 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/pytorch_model.bin\n",
            "Namespace(cache_postfix=None, data_dir='/content/drive/MyDrive/visual-comet/visualcomet_data/', device=device(type='cpu'), do_sample=1, gen_batch_size=1, include_image=True, include_text=True, inference_type='all', length=20, max_seq_len=128, model_name_or_path='/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt', model_type='gpt2_vc', n_gpu=0, no_cuda=False, num_samples=5, output_file=None, overwrite_cache=False, padding_text='', prompt='', seed=42, split='val', task=None, temperature=1.0, top_k=0, top_p=0.9, use_all_dets=False)\n",
            "/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n",
            "*** main val\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data\n",
            "cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "train_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/train_annots.json\n",
            "val_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/val_annots.json\n",
            "test_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/test_annots.json\n",
            "Creating features from dataset file at /content/drive/MyDrive/visual-comet/visualcomet_data with cache file name: /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "val 3\n",
            "Encoding Data:   0% 0/3 [00:00<?, ?it/s]***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is washing carrots', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 20518, 34397, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is washing carrots', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 20518, 34397, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is washing carrots', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 20518, 34397, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 3/3 [00:00<00:00, 813.48it/s]\n",
            "test 41439\n",
            "Encoding Data:   0% 0/41439 [00:00<?, ?it/s]***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 41439/41439 [00:34<00:00, 1195.44it/s]\n",
            "Saving features into cached file %s /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "Only relevant dets\n",
            "Only relevant dets\n",
            "  0% 0/3 [00:00<?, ?it/s]Image: cut/Ex2.jpg\n",
            "Event Text: 1 is washing carrots\n",
            "Place: inside\n",
            "Inference Type: intent\n",
            "Inference Generations: ['wanted to help the other person', 'rehydrate from their hunger', 'get rid of some meat waste', 'wants to help with the salad dressing', 'have a nice meal with a friend']\n",
            " 33% 1/3 [00:53<01:47, 53.61s/it]Image: cut/Ex2.jpg\n",
            "Event Text: 1 is washing carrots\n",
            "Place: inside\n",
            "Inference Type: before\n",
            "Inference Generations: ['own a white belt store', 'get freshwater and feed', 'get into an elaborate dress', 'chop up all the carrots', 'have a cutting board to add vegetables to']\n",
            " 67% 2/3 [01:50<00:55, 55.79s/it]Image: cut/Ex2.jpg\n",
            "Event Text: 1 is washing carrots\n",
            "Place: inside\n",
            "Inference Type: after\n",
            "Inference Generations: ['enjoy the dinner with a friend', 'roast the carrots', 'let them dry', 'inject her finger in the plant for use', 'eat the carrot']\n",
            "100% 3/3 [02:44<00:00, 54.93s/it]\n",
            "Saved to /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n"
          ]
        }
      ],
      "source": [
        "# cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/visual-comet/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt --split val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBKCoEaStLfV"
      },
      "source": [
        "== Ex: Cut an apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R72H17dTuklv",
        "outputId": "cb4a9b15-ddf1-4f2d-df6c-9754a06db5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/12/2023 22:46:43 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "*** main /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/vocab.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/merges.txt\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/added_tokens.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/special_tokens_map.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/tokenizer_config.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|b_img|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|e_img|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|b_ev|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|e_ev|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|b_pl|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|e_pl|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|e_in|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|before|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|intent|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|after|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det0|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det1|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det2|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det3|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det4|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det5|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det6|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det7|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det8|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det9|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det10|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det11|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det12|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det13|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det14|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det15|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det16|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det17|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det18|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det19|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det20|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det21|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det22|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det23|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det24|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det25|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det26|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det27|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det28|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det29|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det30|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det31|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det32|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det33|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det34|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det35|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det36|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det37|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det38|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det39|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det40|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det41|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det42|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det43|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det44|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det45|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det46|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det47|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det48|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Adding <|det49|> to the vocabulary\n",
            "06/12/2023 22:46:43 - INFO - transformers.tokenization_utils -   Assigning ['<|b_img|>', '<|e_img|>', '<|b_ev|>', '<|e_ev|>', '<|b_pl|>', '<|e_pl|>', '<|e_in|>', '<|before|>', '<|intent|>', '<|after|>', '<|det0|>', '<|det1|>', '<|det2|>', '<|det3|>', '<|det4|>', '<|det5|>', '<|det6|>', '<|det7|>', '<|det8|>', '<|det9|>', '<|det10|>', '<|det11|>', '<|det12|>', '<|det13|>', '<|det14|>', '<|det15|>', '<|det16|>', '<|det17|>', '<|det18|>', '<|det19|>', '<|det20|>', '<|det21|>', '<|det22|>', '<|det23|>', '<|det24|>', '<|det25|>', '<|det26|>', '<|det27|>', '<|det28|>', '<|det29|>', '<|det30|>', '<|det31|>', '<|det32|>', '<|det33|>', '<|det34|>', '<|det35|>', '<|det36|>', '<|det37|>', '<|det38|>', '<|det39|>', '<|det40|>', '<|det41|>', '<|det42|>', '<|det43|>', '<|det44|>', '<|det45|>', '<|det46|>', '<|det47|>', '<|det48|>', '<|det49|>'] to the additional_special_tokens key of the tokenizer\n",
            "06/12/2023 22:46:43 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:46:43 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "06/12/2023 22:46:43 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/pytorch_model.bin\n",
            "Namespace(cache_postfix=None, data_dir='/content/drive/MyDrive/visual-comet/visualcomet_data/', device=device(type='cpu'), do_sample=1, gen_batch_size=1, include_image=True, include_text=True, inference_type='all', length=20, max_seq_len=128, model_name_or_path='/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt', model_type='gpt2_vc', n_gpu=0, no_cuda=False, num_samples=5, output_file=None, overwrite_cache=False, padding_text='', prompt='', seed=42, split='val', task=None, temperature=1.0, top_k=0, top_p=0.9, use_all_dets=False)\n",
            "/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n",
            "*** main val\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data\n",
            "cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "train_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/train_annots.json\n",
            "val_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/val_annots.json\n",
            "test_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/test_annots.json\n",
            "Creating features from dataset file at /content/drive/MyDrive/visual-comet/visualcomet_data with cache file name: /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "val 3\n",
            "Encoding Data:   0% 0/3 [00:00<?, ?it/s]***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting an apple', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 281, 17180, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting an apple', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 281, 17180, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is cutting an apple', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 7720, 281, 17180, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 3/3 [00:00<00:00, 758.83it/s]\n",
            "test 41439\n",
            "Encoding Data:   0% 0/41439 [00:00<?, ?it/s]***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 41439/41439 [00:32<00:00, 1287.06it/s]\n",
            "Saving features into cached file %s /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "Only relevant dets\n",
            "Only relevant dets\n",
            "  0% 0/3 [00:00<?, ?it/s]Image: cut/Ex3.jpg\n",
            "Event Text: 1 is cutting an apple\n",
            "Place: inside\n",
            "Inference Type: intent\n",
            "Inference Generations: ['wanted to eat a lot of apple', 'enjoy the food', 'get ready for dinner', 'taste it', 'cut the apple']\n",
            " 33% 1/3 [00:56<01:53, 56.74s/it]Image: cut/Ex3.jpg\n",
            "Event Text: 1 is cutting an apple\n",
            "Place: inside\n",
            "Inference Type: before\n",
            "Inference Generations: ['get an apple', 'get some butter and cream', 'get her knives', 'unscrew the apple', 'buy the apple']\n",
            " 67% 2/3 [01:52<00:56, 56.18s/it]Image: cut/Ex3.jpg\n",
            "Event Text: 1 is cutting an apple\n",
            "Place: inside\n",
            "Inference Type: after\n",
            "Inference Generations: ['receive the apple with a treat', 'enjoy the rest of her day', 'stand back up', 'wipe her eyes with a napkin', 'smile at the other person']\n",
            "100% 3/3 [02:46<00:00, 55.52s/it]\n",
            "Saved to /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n"
          ]
        }
      ],
      "source": [
        "# cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/visual-comet/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt --split val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTQa7TBOwSlb"
      },
      "source": [
        "== Ex: Boil broccoli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQKKG8O0wXAh",
        "outputId": "8d8de538-0c30-4dee-d1d1-0b7ecfb0a0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/12/2023 22:50:42 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "*** main /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/vocab.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/merges.txt\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/added_tokens.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/special_tokens_map.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/tokenizer_config.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|b_img|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|e_img|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|b_ev|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|e_ev|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|b_pl|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|e_pl|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|e_in|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|before|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|intent|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|after|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det0|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det1|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det2|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det3|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det4|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det5|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det6|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det7|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det8|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det9|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det10|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det11|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det12|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det13|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det14|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det15|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det16|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det17|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det18|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det19|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det20|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det21|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det22|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det23|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det24|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det25|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det26|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det27|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det28|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det29|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det30|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det31|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det32|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det33|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det34|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det35|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det36|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det37|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det38|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det39|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det40|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det41|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det42|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det43|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det44|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det45|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det46|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det47|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det48|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Adding <|det49|> to the vocabulary\n",
            "06/12/2023 22:50:42 - INFO - transformers.tokenization_utils -   Assigning ['<|b_img|>', '<|e_img|>', '<|b_ev|>', '<|e_ev|>', '<|b_pl|>', '<|e_pl|>', '<|e_in|>', '<|before|>', '<|intent|>', '<|after|>', '<|det0|>', '<|det1|>', '<|det2|>', '<|det3|>', '<|det4|>', '<|det5|>', '<|det6|>', '<|det7|>', '<|det8|>', '<|det9|>', '<|det10|>', '<|det11|>', '<|det12|>', '<|det13|>', '<|det14|>', '<|det15|>', '<|det16|>', '<|det17|>', '<|det18|>', '<|det19|>', '<|det20|>', '<|det21|>', '<|det22|>', '<|det23|>', '<|det24|>', '<|det25|>', '<|det26|>', '<|det27|>', '<|det28|>', '<|det29|>', '<|det30|>', '<|det31|>', '<|det32|>', '<|det33|>', '<|det34|>', '<|det35|>', '<|det36|>', '<|det37|>', '<|det38|>', '<|det39|>', '<|det40|>', '<|det41|>', '<|det42|>', '<|det43|>', '<|det44|>', '<|det45|>', '<|det46|>', '<|det47|>', '<|det48|>', '<|det49|>'] to the additional_special_tokens key of the tokenizer\n",
            "06/12/2023 22:50:42 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:50:42 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "06/12/2023 22:50:42 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/pytorch_model.bin\n",
            "Namespace(cache_postfix=None, data_dir='/content/drive/MyDrive/visual-comet/visualcomet_data/', device=device(type='cpu'), do_sample=1, gen_batch_size=1, include_image=True, include_text=True, inference_type='all', length=20, max_seq_len=128, model_name_or_path='/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt', model_type='gpt2_vc', n_gpu=0, no_cuda=False, num_samples=5, output_file=None, overwrite_cache=False, padding_text='', prompt='', seed=42, split='val', task=None, temperature=1.0, top_k=0, top_p=0.9, use_all_dets=False)\n",
            "/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n",
            "*** main val\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data\n",
            "cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "train_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/train_annots.json\n",
            "val_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/val_annots.json\n",
            "test_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/test_annots.json\n",
            "Creating features from dataset file at /content/drive/MyDrive/visual-comet/visualcomet_data with cache file name: /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "val 3\n",
            "Encoding Data:   0% 0/3 [00:00<?, ?it/s]***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is boiling broccoli', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 24372, 44653, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is boiling broccoli', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 24372, 44653, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is boiling broccoli', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 24372, 44653, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 3/3 [00:00<00:00, 1420.67it/s]\n",
            "test 41439\n",
            "Encoding Data:   0% 0/41439 [00:00<?, ?it/s]***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 41439/41439 [00:32<00:00, 1264.91it/s]\n",
            "Saving features into cached file %s /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "Only relevant dets\n",
            "Only relevant dets\n",
            "  0% 0/3 [00:00<?, ?it/s]Image: cut/Ex4.jpg\n",
            "Event Text: 1 is boiling broccoli\n",
            "Place: inside\n",
            "Inference Type: intent\n",
            "Inference Generations: ['stir the broccoli', 'chop the vegetables', 'be organized', 'enjoy her meal', 'make a dish']\n",
            " 33% 1/3 [00:56<01:53, 56.99s/it]Image: cut/Ex4.jpg\n",
            "Event Text: 1 is boiling broccoli\n",
            "Place: inside\n",
            "Inference Type: before\n",
            "Inference Generations: ['get the ingredients together', 'get ingredients from the refrigerator', 'be hungry', 'unscrew the vegetables', 'dig a huge hole in the garden']\n",
            " 67% 2/3 [01:52<00:56, 56.13s/it]Image: cut/Ex4.jpg\n",
            "Event Text: 1 is boiling broccoli\n",
            "Place: inside\n",
            "Inference Type: after\n",
            "Inference Generations: ['chop the broccoli into a large bowl', 'chop the pepper', 'put food into the mouth of the broccoli', 'stir the mixture well', 'do a sort of will on her plate']\n",
            "100% 3/3 [02:50<00:00, 56.94s/it]\n",
            "Saved to /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n"
          ]
        }
      ],
      "source": [
        "# cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/visual-comet/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt --split val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UURYAp3qtLhs"
      },
      "source": [
        "== Ex: Pour drink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osvt7klvQRvL",
        "outputId": "a96d3416-5e0e-4e7d-dadb-4ef1920478e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06/12/2023 22:58:32 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "*** main /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/vocab.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/merges.txt\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/added_tokens.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/special_tokens_map.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/tokenizer_config.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|b_img|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|e_img|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|b_ev|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|e_ev|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|b_pl|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|e_pl|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|e_in|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|before|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|intent|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|after|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det0|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det1|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det2|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det3|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det4|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det5|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det6|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det7|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det8|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det9|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det10|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det11|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det12|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det13|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det14|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det15|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det16|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det17|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det18|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det19|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det20|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det21|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det22|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det23|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det24|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det25|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det26|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det27|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det28|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det29|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det30|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det31|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det32|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det33|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det34|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det35|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det36|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det37|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det38|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det39|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det40|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det41|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det42|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det43|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det44|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det45|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det46|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det47|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det48|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Adding <|det49|> to the vocabulary\n",
            "06/12/2023 22:58:32 - INFO - transformers.tokenization_utils -   Assigning ['<|b_img|>', '<|e_img|>', '<|b_ev|>', '<|e_ev|>', '<|b_pl|>', '<|e_pl|>', '<|e_in|>', '<|before|>', '<|intent|>', '<|after|>', '<|det0|>', '<|det1|>', '<|det2|>', '<|det3|>', '<|det4|>', '<|det5|>', '<|det6|>', '<|det7|>', '<|det8|>', '<|det9|>', '<|det10|>', '<|det11|>', '<|det12|>', '<|det13|>', '<|det14|>', '<|det15|>', '<|det16|>', '<|det17|>', '<|det18|>', '<|det19|>', '<|det20|>', '<|det21|>', '<|det22|>', '<|det23|>', '<|det24|>', '<|det25|>', '<|det26|>', '<|det27|>', '<|det28|>', '<|det29|>', '<|det30|>', '<|det31|>', '<|det32|>', '<|det33|>', '<|det34|>', '<|det35|>', '<|det36|>', '<|det37|>', '<|det38|>', '<|det39|>', '<|det40|>', '<|det41|>', '<|det42|>', '<|det43|>', '<|det44|>', '<|det45|>', '<|det46|>', '<|det47|>', '<|det48|>', '<|det49|>'] to the additional_special_tokens key of the tokenizer\n",
            "06/12/2023 22:58:32 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/config.json\n",
            "06/12/2023 22:58:32 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2VisionAttentiveLMHead\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_event\": 39,\n",
            "  \"max_inference\": 23,\n",
            "  \"max_length\": 20,\n",
            "  \"max_place\": 22,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bbox\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_person_ids\": true,\n",
            "  \"use_subject_ids\": true,\n",
            "  \"vocab_size\": 50317\n",
            "}\n",
            "\n",
            "06/12/2023 22:58:32 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/pytorch_model.bin\n",
            "Namespace(cache_postfix=None, data_dir='/content/drive/MyDrive/visual-comet/visualcomet_data/', device=device(type='cpu'), do_sample=1, gen_batch_size=1, include_image=True, include_text=True, inference_type='all', length=20, max_seq_len=128, model_name_or_path='/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt', model_type='gpt2_vc', n_gpu=0, no_cuda=False, num_samples=5, output_file=None, overwrite_cache=False, padding_text='', prompt='', seed=42, split='val', task=None, temperature=1.0, top_k=0, top_p=0.9, use_all_dets=False)\n",
            "/content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n",
            "*** main val\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data\n",
            "cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "train_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/train_annots.json\n",
            "val_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/val_annots.json\n",
            "test_annots.json\n",
            "/content/drive/MyDrive/visual-comet/visualcomet_data/test_annots.json\n",
            "Creating features from dataset file at /content/drive/MyDrive/visual-comet/visualcomet_data with cache file name: /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "val 3\n",
            "Encoding Data:   0% 0/3 [00:00<?, ?it/s]***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is pouring drink in a cup', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 23147, 4144, 287, 257, 6508, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is pouring drink in a cup', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 23147, 4144, 287, 257, 6508, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: val *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> is pouring drink in a cup', '<|e_ev|>'], ['<|b_pl|>', 'inside', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 23147, 4144, 287, 257, 6508, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 48787, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 3/3 [00:00<00:00, 901.48it/s]\n",
            "test 41439\n",
            "Encoding Data:   0% 0/41439 [00:00<?, ?it/s]***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', '<|det1|> and <|det2|> are pictures of a man and woman sticking out of a bag', '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|after|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 392, 50269, 533, 5986, 286, 257, 582, 290, 2415, 17274, 503, 286, 257, 6131, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50266, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|intent|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50265, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "***** Example Instance for Split: test *****\n",
            "Text: [['<|b_img|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '<|e_img|>'], ['<|b_ev|>', \"<|det1|> is half a woman  's face protruding from the top of a suitcase\", '<|e_ev|>'], ['<|b_pl|>', 'in an airport', '<|e_pl|>'], ['<|before|>']]\n",
            "Tokenized Text: [50257, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50258, 50259, 50268, 271, 2063, 257, 2415, 220, 705, 82, 1986, 39701, 26570, 422, 262, 1353, 286, 257, 45391, 50260, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50261, 259, 281, 9003, 50262, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50264, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n",
            "********\n",
            "\n",
            "Encoding Data: 100% 41439/41439 [00:29<00:00, 1403.86it/s]\n",
            "Saving features into cached file %s /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
            "Only relevant dets\n",
            "Only relevant dets\n",
            "  0% 0/3 [00:00<?, ?it/s]Image: cut/Ex6.jpg\n",
            "Event Text: 1 is pouring drink in a cup\n",
            "Place: inside\n",
            "Inference Type: intent\n",
            "Inference Generations: ['perform a proper job', 'perform his job', 'get drunk', 'quench thirst', 'drink something']\n",
            " 33% 1/3 [00:58<01:57, 58.50s/it]Image: cut/Ex6.jpg\n",
            "Event Text: 1 is pouring drink in a cup\n",
            "Place: inside\n",
            "Inference Type: before\n",
            "Inference Generations: ['get the drink out of a container', 'get hired to do some bartending', 'get orders from customers', 'attend the party', 'make a drink']\n",
            " 67% 2/3 [01:54<00:56, 56.76s/it]Image: cut/Ex6.jpg\n",
            "Event Text: 1 is pouring drink in a cup\n",
            "Place: inside\n",
            "Inference Type: after\n",
            "Inference Generations: ['wipe the cup with a towel', 'welcome guests to their favorite bar', 'scrub more ingredients into the glass', 'wipe down the countertop', 'cut the alcohol into small pieces']\n",
            "100% 3/3 [02:50<00:00, 56.76s/it]\n",
            "Saved to /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt/val_sample_1_num_5_top_k_0_top_p_0.9.json\n"
          ]
        }
      ],
      "source": [
        " # cell 5\n",
        "# script to run predictiontions from checkpoint for custom\n",
        "!rm /content/drive/MyDrive/visual-comet/visualcomet_data/cached_lm_max_seq_len_128_mode_inference_include_text_true_generation\n",
        "!python3.6 ./scripts/run_generation.py --data_dir /content/drive/MyDrive/visual-comet/visualcomet_data/ --model_name_or_path /content/drive/MyDrive/visual-comet/experiments/image-inference-80000-ckpt --split val"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}